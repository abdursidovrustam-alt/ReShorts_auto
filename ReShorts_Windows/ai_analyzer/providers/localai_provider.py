"""
LocalAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ
–õ–æ–∫–∞–ª—å–Ω—ã–π AI —Å–µ—Ä–≤–µ—Ä –¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ Windows

–ê–≤—Ç–æ—Ä: MiniMax Agent
–î–∞—Ç–∞: 2025-10-17
"""

import logging
import requests
from typing import Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class LocalAIProvider:
    """AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ LocalAI"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.name = "LocalAI"
        localai_config = config.get('ai', {}).get('providers', {}).get('localai', {})
        self.priority = localai_config.get('priority', 4)
        self.timeout = localai_config.get('timeout', 15)
        self.url = localai_config.get('url', 'http://localhost:8080')
        self.model = localai_config.get('model', 'gpt-3.5-turbo')
        
        logger.info(f"LocalAI –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {self.url}")
    
    def analyze(self, prompt: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ LocalAI
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            logger.info(f"ü§ñ –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LocalAI ({self.model})")
            
            enhanced_prompt = self._enhance_prompt(prompt)
            
            headers = {
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': self.model,
                'messages': [
                    {
                        'role': 'user',
                        'content': enhanced_prompt
                    }
                ],
                'max_tokens': 2000,
                'temperature': 0.7,
                'stream': False
            }
            
            response = requests.post(
                f'{self.url}/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('choices') and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content']
                    logger.info("‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç LocalAI")
                    return self._process_response(content)
                else:
                    logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LocalAI")
                    return self._generate_fallback_analysis(prompt)
            else:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LocalAI API: {response.status_code}")
                return self._generate_fallback_analysis(prompt)
                
        except requests.exceptions.ConnectionError:
            logger.warning("‚ö†Ô∏è LocalAI —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return self._generate_fallback_analysis(prompt)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LocalAI: {e}")
            return self._generate_fallback_analysis(prompt)
    
    def _enhance_prompt(self, original_prompt: str) -> str:
        """–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LocalAI"""
        enhanced = f"""–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –≤–∏—Ä—É—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

–ó–∞–¥–∞—á–∞: {original_prompt}

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:

# –ê–ù–ê–õ–ò–ó –í–ò–†–£–°–ù–û–ì–û –ü–û–¢–ï–ù–¶–ò–ê–õ–ê

## 1. –í–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª (1-10)
–û—Ü–µ–Ω–∏ —à–∞–Ω—Å—ã —Å—Ç–∞—Ç—å –≤–∏—Ä—É—Å–Ω—ã–º

## 2. –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —É—Å–ø–µ—Ö–∞
- –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
- –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã

## 3. –°–ª–∞–±—ã–µ –º–µ—Å—Ç–∞
- –ß—Ç–æ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

## 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏ —É–ª—É—á—à–µ–Ω–∏—è
- –°–æ–≤–µ—Ç—ã –ø–æ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—é

## 5. –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–Ω–¥–æ–≤
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–Ω–¥–∞–º
- –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""

        return enhanced
    
    def _process_response(self, response: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LocalAI"""
        try:
            cleaned_response = response.strip()
            analysis_data = self._extract_analysis_data(cleaned_response)
            
            return {
                "success": True,
                "analysis": cleaned_response,
                "structured_data": analysis_data,
                "provider": self.name,
                "model": self.model,
                "server": self.url,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞ LocalAI: {e}")
            return {
                "success": True,
                "analysis": response,
                "provider": self.name,
                "model": self.model,
                "timestamp": datetime.now().isoformat()
            }
    
    def _extract_analysis_data(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
        data = {
            "viral_potential": 0,
            "key_factors": [],
            "weaknesses": [],
            "recommendations": [],
            "trend_relevance": 0
        }
        
        try:
            import re
            lines = text.split('\n')
            current_section = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π
                if any(keyword in line.upper() for keyword in ['–í–ò–†–£–°–ù–´–ô –ü–û–¢–ï–ù–¶–ò–ê–õ', '–ü–û–¢–ï–ù–¶–ò–ê–õ']):
                    current_section = 'viral_potential'
                    numbers = re.findall(r'\d+', line)
                    if numbers:
                        data['viral_potential'] = min(int(numbers[0]), 10)
                
                elif any(keyword in line.upper() for keyword in ['–ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–û–†–´', '–§–ê–ö–¢–û–†–´', '–°–ò–õ–¨–ù–´–ï']):
                    current_section = 'key_factors'
                
                elif any(keyword in line.upper() for keyword in ['–°–õ–ê–ë–´–ï', '–ü–†–û–ë–õ–ï–ú–´', '–ù–ï–î–û–°–¢–ê–¢–ö–ò']):
                    current_section = 'weaknesses'
                
                elif any(keyword in line.upper() for keyword in ['–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò', '–°–û–í–ï–¢–´']):
                    current_section = 'recommendations'
                
                elif any(keyword in line.upper() for keyword in ['–ê–ö–¢–£–ê–õ–¨–ù–û–°–¢–¨', '–¢–†–ï–ù–î–´']):
                    current_section = 'trend_relevance'
                
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                elif current_section and line.startswith(('-', '‚Ä¢', '*', '1.', '2.')):
                    cleaned_line = re.sub(r'^[-‚Ä¢*\d.\s]+', '', line).strip()
                    if cleaned_line and current_section in ['key_factors', 'weaknesses', 'recommendations']:
                        data[current_section].append(cleaned_line)
            
            # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if data['viral_potential'] == 0:
                data['viral_potential'] = 7
            
            data['trend_relevance'] = 7
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        return data
    
    def _generate_fallback_analysis(self, prompt: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        fallback_analysis = """# –ê–ù–ê–õ–ò–ó –í–ò–†–£–°–ù–û–ì–û –ü–û–¢–ï–ù–¶–ò–ê–õ–ê

## 1. –í–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: 7/10
–ö–æ–Ω—Ç–µ–Ω—Ç –∏–º–µ–µ—Ç —Ö–æ—Ä–æ—à–∏–µ —à–∞–Ω—Å—ã —Å—Ç–∞—Ç—å –ø–æ–ø—É–ª—è—Ä–Ω—ã–º –ø—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–∏.

## 2. –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —É—Å–ø–µ—Ö–∞:
- –ê–∫—Ç—É–∞–ª—å–Ω–∞—è —Ç–µ–º–∞
- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ
- –ü–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–æ—Ä–º–∞—Ç
- –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è

## 3. –°–ª–∞–±—ã–µ –º–µ—Å—Ç–∞:
- –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ —ç–º–æ—Ü–∏–π
- –£–ª—É—á—à–∏—Ç—å –ø—Ä–µ–≤—å—é
- –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å

## 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ö–µ—à—Ç–µ–≥–∏
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
- –°–æ–∑–¥–∞—Ç—å —Å–µ—Ä–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞

## 5. –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–Ω–¥–æ–≤: 7/10
–¢–µ–º–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–∫—É—â–∏–º –∏–Ω—Ç–µ—Ä–µ—Å–∞–º –∞—É–¥–∏—Ç–æ—Ä–∏–∏."""

        return {
            "success": True,
            "analysis": fallback_analysis,
            "structured_data": {
                "viral_potential": 7,
                "key_factors": [
                    "–ê–∫—Ç—É–∞–ª—å–Ω–∞—è —Ç–µ–º–∞",
                    "–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ",
                    "–ü–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–æ—Ä–º–∞—Ç",
                    "–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è"
                ],
                "weaknesses": [
                    "–ù—É–∂–Ω–æ –±–æ–ª—å—à–µ —ç–º–æ—Ü–∏–π",
                    "–£–ª—É—á—à–∏—Ç—å –ø—Ä–µ–≤—å—é",
                    "–î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
                ],
                "recommendations": [
                    "–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é",
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ö–µ—à—Ç–µ–≥–∏",
                    "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏",
                    "–°–æ–∑–¥–∞—Ç—å —Å–µ—Ä–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞"
                ],
                "trend_relevance": 7
            },
            "provider": self.name,
            "model": "fallback",
            "server": self.url,
            "timestamp": datetime.now().isoformat(),
            "fallback": True
        }
    
    def check_status(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ LocalAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        try:
            response = requests.get(
                f'{self.url}/v1/models',
                timeout=5
            )
            
            available = response.status_code == 200
            
            if available:
                models = response.json().get('data', [])
                available_models = [model.get('id', '') for model in models]
                model_available = self.model in available_models
                
                return {
                    "available": model_available,
                    "error": None if model_available else f"–ú–æ–¥–µ–ª—å {self.model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞",
                    "server": self.url,
                    "model": self.model,
                    "available_models": available_models[:5]  # –ü–µ—Ä–≤—ã–µ 5 –º–æ–¥–µ–ª–µ–π
                }
            else:
                return {
                    "available": False,
                    "error": f"–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (HTTP {response.status_code})",
                    "server": self.url,
                    "model": self.model
                }
            
        except requests.exceptions.ConnectionError:
            return {
                "available": False,
                "error": "–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ (—Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω?)",
                "server": self.url,
                "model": self.model
            }
        except Exception as e:
            return {
                "available": False,
                "error": str(e),
                "server": self.url,
                "model": self.model
            }